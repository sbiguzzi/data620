{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f959c0e",
   "metadata": {},
   "source": [
    "# Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73e962",
   "metadata": {},
   "source": [
    "## Team members: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82b2a3",
   "metadata": {},
   "source": [
    "#### <font color='sapphire'>Dennis Pong, Stefano Biguzzi, Ian Costello </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94140ce",
   "metadata": {},
   "source": [
    "### Natural Language Processing with Python, exercise 6.10.2 (P. 257)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d40529",
   "metadata": {},
   "source": [
    "#### Problem: Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can.\n",
    "\n",
    "#### Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "\n",
    "#### How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcc018",
   "metadata": {},
   "source": [
    "\n",
    "## import packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e013d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !pip install emoji --upgrade\n",
    "# !pip install gender-guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14591aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "from nltk.metrics import ConfusionMatrix, accuracy, precision, recall, f_measure\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji \n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "import gender_guesser.detector as gender\n",
    "    \n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16bb9cf",
   "metadata": {},
   "source": [
    "## Loading of Data from the Names Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6fec191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2943 male names.\n",
      "There are 5001 female names.\n"
     ]
    }
   ],
   "source": [
    "# Load the names corpus, use random to shuffle the names\n",
    "# !pwd\n",
    "# nltk.download()\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# check the corpus, there are two files, female.txt and male.txt\n",
    "nltk.corpus.names.fileids()\n",
    "\n",
    "print(f\"There are {len(names.words('male.txt'))} male names.\")\n",
    "print(f\"There are {len(names.words('female.txt'))} female names.\")\n",
    "# concatenate the lists \n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "                 [(name, 'female') for name in names.words('female.txt')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9cf7cd",
   "metadata": {},
   "source": [
    "###### we see that the male to female ratios is currently at  ~ (59:100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ef2a591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aamir', 'male'),\n",
       " ('Aaron', 'male'),\n",
       " ('Abbey', 'male'),\n",
       " ('Abbie', 'male'),\n",
       " ('Abbot', 'male'),\n",
       " ('Abbott', 'male'),\n",
       " ('Abby', 'male'),\n",
       " ('Abdel', 'male'),\n",
       " ('Abdul', 'male'),\n",
       " ('Abdulkarim', 'male')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724cbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random shuffling of the list \n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49c9237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Antonina', 'female'),\n",
       " ('Lynsey', 'female'),\n",
       " ('Lois', 'female'),\n",
       " ('Nate', 'male'),\n",
       " ('Holly-Anne', 'female'),\n",
       " ('Bailie', 'male'),\n",
       " ('Leslie', 'male'),\n",
       " ('Melina', 'female'),\n",
       " ('Celinka', 'female'),\n",
       " ('Bernhard', 'male')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab976edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7579"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract name from the list, and check for length\n",
    "len(set(item[0] for item in labeled_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef06804",
   "metadata": {},
   "source": [
    "### We've to remove names that is labeled as both male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb2904b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gabriel', 'female'),\n",
       " ('Gabriel', 'male'),\n",
       " ('Jude', 'female'),\n",
       " ('Jude', 'male'),\n",
       " ('Pen', 'female'),\n",
       " ('Pen', 'male')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 examples \n",
    "sorted([item for item in labeled_names if item[0] in [\"Jude\",\"Pen\",\"Gabriel\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91079ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the duplicates, and check for the total number of unique names\n",
    "names_freq = nltk.FreqDist(item[0] for item in labeled_names)\n",
    "nm_dupes = [(k,v) for k,v in names_freq.items() if v >1]\n",
    "nm_dupes\n",
    "\n",
    "first_names_to_be_removed = [item[0] for item in nm_dupes]\n",
    "labeled_names_dedupped = [item for item in labeled_names if not item[0] in first_names_to_be_removed]\n",
    "\n",
    "len(labeled_names_dedupped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20257d64",
   "metadata": {},
   "source": [
    "### With the removal of doubly-labeled names, we're ready to do splitting of the datasets for test, dev-test, and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "646b3ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set = 6214\n",
      "Dev-test (or the valiation) Set = 500\n",
      "Test Set = 500\n"
     ]
    }
   ],
   "source": [
    "test = labeled_names_dedupped[0:500]\n",
    "dev_test = labeled_names_dedupped[500:1000]\n",
    "train = labeled_names_dedupped[1000:]\n",
    "\n",
    "# Confirm the size of the three subsets\n",
    "print(\"Training Set = {}\".format(len(train)))\n",
    "print(\"Dev-test (or the valiation) Set = {}\".format(len(dev_test)))\n",
    "print(\"Test Set = {}\".format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f2313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eb6b47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'female': 3996, 'male': 2218})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the male/female category\n",
    "train_dist = [cat  for (nm, cat) in train]\n",
    "nltk.FreqDist(train_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f54ddf",
   "metadata": {},
   "source": [
    "male to female ratios is currently at ~ (56:100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-mason",
   "metadata": {},
   "source": [
    "#### Because of the male-to-feamle ratios that is very imbalanced in terms of labels, we normally deemed accuracy not the most appropriate measure as it doesn't depict the actual prediction accuracy for the least represented class, male, in this case. In addition to accuracy, recall and precision are reported for each class via a custom function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-capture",
   "metadata": {},
   "source": [
    "- Precision or positive predictive value  \n",
    "${\\displaystyle \\mathrm {PPV} ={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FP} }}}$ , i.e., higher precision means there are fewer false positives.\n",
    "\n",
    "- Recall or true positive rate  \n",
    "${\\displaystyle \\mathrm {TPR} = {\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }} }$, i.e., higher recall means there are fewer false negatives.\n",
    "\n",
    "- F1 score\n",
    "is the harmonic mean of precision and sensitivity:  \n",
    "${\\displaystyle \\mathrm {F} _{1}=2\\times {\\frac {\\mathrm {PPV} \\times \\mathrm {TPR} }{\\mathrm {PPV} +\\mathrm {TPR} }}={\\frac {2\\mathrm {TP} }{2\\mathrm {TP} +\\mathrm {FP} +\\mathrm {FN} }}}{\\displaystyle \\mathrm {F} _{1}=2\\times {\\frac {\\mathrm {PPV} \\times \\mathrm {TPR} }{\\mathrm {PPV} +\\mathrm {TPR} }}={\\frac {2\\mathrm {TP} }{2\\mathrm {TP} +\\mathrm {FP} +\\mathrm {FN} }}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-timer",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification\n",
    "#### We are going to look at the 8 distinct features functions and evaluate them with all the them using a set of performance metrics to determine their relevance to what we're trying to predict using NB classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1f541b",
   "metadata": {},
   "source": [
    "### Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e84670",
   "metadata": {},
   "source": [
    "### 1st feature: last letter of the given name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c63e0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "  return {'last_letter': name[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e7fe90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'y'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features(\"Mary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-confidence",
   "metadata": {},
   "source": [
    "### <b> Building a function for easier bundling of performance metrics </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contrary-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(model, training_set, digits=4):\n",
    "    \"\"\"Prints the precision, recall, and F-measure (or F1 score) of an NLTK Naive Bayes classifer.\n",
    "       alpha for F-measure is default to 0.5\n",
    "    \"\"\"\n",
    "    reference = collections.defaultdict(set)\n",
    "    test = collections.defaultdict(set)\n",
    "    \n",
    "    for i, (features, label) in enumerate(training_set):\n",
    "        reference[label].add(i)\n",
    "        pred = model.classify(features)\n",
    "        test[pred].add(i)\n",
    "        \n",
    "    m_precision = round(precision(reference['male'], test['male']), digits)\n",
    "    f_precision = round(precision(reference['female'], test['female']), digits)\n",
    "    \n",
    "    m_recall = round(recall(reference['male'], test['male']), digits)\n",
    "    f_recall = round( recall(reference['female'], test['female']), digits)\n",
    "    \n",
    "    m_f_measure = round(f_measure(reference['male'], test['male']), digits)\n",
    "    f_f_measure = round(f_measure(reference['female'], test['female']), digits)\n",
    "    \n",
    "    print('Male precision: ', m_precision)\n",
    "    print('Female precision: ', f_precision)\n",
    "    print('Male recall: ', m_recall)\n",
    "    print('Female recall: ', f_recall)\n",
    "    printmd('Male F1 Score: '); print(m_f_measure)\n",
    "    printmd('Female F1 Score: '); print(f_f_measure)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94eb40db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is\n",
      "0.75\n",
      "Test accuracy is\n",
      "0.822\n",
      "\n",
      "Performance metrics for training set: \n",
      "\n",
      "Male precision:  0.7005\n",
      "Female precision:  0.8418\n",
      "Male recall:  0.7191\n",
      "Female recall:  0.8293\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7097\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8355\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), g) for (n,g) in train]\n",
    "dev_test_set = [(gender_features(n), g) for (n,g) in dev_test]\n",
    "test_set = [(gender_features(n), g) for (n,g) in test]\n",
    "nb1 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Validation accuracy is')\n",
    "print(nltk.classify.accuracy(nb1, dev_test_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb1, test_set))\n",
    "print(\"\")\n",
    "print(\"Performance metrics for training set: \\n\", )\n",
    "performance_metrics(nb1, train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "detailed-madonna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for validation set: \n",
      "\n",
      "Male precision:  0.6592\n",
      "Female precision:  0.8006\n",
      "Male recall:  0.6484\n",
      "Female recall:  0.8082\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6537\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8044\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for validation set: \\n\", )\n",
    "performance_metrics(nb1, dev_test_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-portable",
   "metadata": {},
   "source": [
    "There is a noticeable dropoff for Male F1 Score while Female F1 Score saw a slight decrease. That tells me that there is no a strong indication of overfitting with this NB classfier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7ffaa",
   "metadata": {},
   "source": [
    "### 2nd feature: kitchen sink approach - first_letter and last_letter are printed. Then out of all alphabets, whether it's present with that letter or not, and what's the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7734e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6708abc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'j',\n",
       " 'last_letter': 'n',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 1,\n",
       " 'has(h)': True,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 1,\n",
       " 'has(j)': True,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features2('John') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bab28fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is\n",
      "0.8\n",
      "Test accuracy is\n",
      "0.798\n",
      "\n",
      "Performance metrics for training set: \n",
      "\n",
      "Male precision:  0.7359\n",
      "Female precision:  0.8458\n",
      "Male recall:  0.7187\n",
      "Female recall:  0.8569\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8513\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features2(n), g) for (n,g) in train]\n",
    "dev_test_set = [(gender_features2(n), g) for (n,g) in dev_test]\n",
    "test_set = [(gender_features2(n), g) for (n,g) in test]\n",
    "nb2 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Validation accuracy is')\n",
    "print(nltk.classify.accuracy(nb2, dev_test_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb2, test_set))\n",
    "print(\"\")\n",
    "print(\"Performance metrics for training set: \\n\", )\n",
    "performance_metrics(nb2, train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "younger-contents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for validation set: \n",
      "\n",
      "Male precision:  0.7384\n",
      "Female precision:  0.8323\n",
      "Male recall:  0.6978\n",
      "Female recall:  0.8585\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7175\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8452\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for validation set: \\n\", )\n",
    "performance_metrics(nb2, dev_test_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-ebony",
   "metadata": {},
   "source": [
    "There is a slight dropoff for Male F1 Score while Female F1 Score saw a slight decrease. It is still not at an alarming level where as far as overfitting is concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-collins",
   "metadata": {},
   "source": [
    "### 3rd feature: Last letter and last 2 letters of name\n",
    "Some suffixes that are more than one letter can be indicative of name genders. For example, names ending in yn appear to be predominantly female, despite the fact that names ending in n tend to be male; and names ending in ch are usually male, even though names that end in h tend to be female. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "alternate-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features3(name):\n",
    "    return {'suffix1': name[-1:],\n",
    "            'suffix2': name[-2:]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "vocational-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'female': 73, 'male': 6})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix2_yn_dist = [item[1] for item in labeled_names_dedupped if gender_features3(item[0])['suffix2'] == 'yn']\n",
    "nltk.FreqDist(suffix2_yn_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "medium-portable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡It's indeed true that suffixes ending in 'yn' is overwhemlingly more likely to be a female\n"
     ]
    }
   ],
   "source": [
    "print(emoji.emojize(':bulb:It\\'s indeed true that suffixes ending in \\'yn\\' is overwhemlingly more likely to be a female',\n",
    "                    use_aliases=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "alien-equivalent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is\n",
      "0.766\n",
      "Test accuracy is\n",
      "0.834\n",
      "\n",
      "Performance metrics for training set: \n",
      "\n",
      "Male precision:  0.7441\n",
      "Female precision:  0.8671\n",
      "Male recall:  0.7642\n",
      "Female recall:  0.8541\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8606\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features3(n), g) for (n,g) in train]\n",
    "dev_test_set = [(gender_features3(n), g) for (n,g) in dev_test]\n",
    "test_set = [(gender_features3(n), g) for (n,g) in test]\n",
    "nb3 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Validation accuracy is')\n",
    "print(nltk.classify.accuracy(nb3, dev_test_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb3, test_set))\n",
    "print(\"\")\n",
    "print(\"Performance metrics for training set: \\n\", )\n",
    "performance_metrics(nb3, train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hearing-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for validation set: \n",
      "\n",
      "Male precision:  0.6757\n",
      "Female precision:  0.819\n",
      "Male recall:  0.6868\n",
      "Female recall:  0.8113\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6812\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8152\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for validation set: \\n\", )\n",
    "performance_metrics(nb3, dev_test_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-construction",
   "metadata": {},
   "source": [
    "There is a noticeable dropoff for Male F1 Score while Female F1 Score saw a 5% increase. No strong evidence for overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-wallpaper",
   "metadata": {},
   "source": [
    "If you're interested in the most informative features of the NB classifier built with the training set, there is a built-in function called show_most_informative_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "loose-wyoming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 suffix2 = 'ia'           female : male   =     81.5 : 1.0\n",
      "                 suffix1 = 'k'              male : female =     79.7 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     67.1 : 1.0\n",
      "                 suffix2 = 'us'             male : female =     62.6 : 1.0\n",
      "                 suffix2 = 'rt'             male : female =     56.7 : 1.0\n",
      "                 suffix2 = 'ra'           female : male   =     53.8 : 1.0\n",
      "                 suffix2 = 'ta'           female : male   =     38.2 : 1.0\n",
      "                 suffix2 = 'ch'             male : female =     26.3 : 1.0\n",
      "                 suffix2 = 'do'             male : female =     25.1 : 1.0\n",
      "                 suffix2 = 'rd'             male : female =     24.8 : 1.0\n",
      "                 suffix2 = 'ld'             male : female =     21.4 : 1.0\n",
      "                 suffix2 = 'os'             male : female =     19.3 : 1.0\n",
      "                 suffix1 = 'p'              male : female =     18.6 : 1.0\n",
      "                 suffix1 = 'f'              male : female =     16.2 : 1.0\n",
      "                 suffix2 = 'io'             male : female =     15.1 : 1.0\n",
      "                 suffix1 = 'm'              male : female =     13.3 : 1.0\n",
      "                 suffix2 = 'di'           female : male   =     13.1 : 1.0\n",
      "                 suffix2 = 'as'             male : female =     12.8 : 1.0\n",
      "                 suffix2 = 'ka'           female : male   =     12.4 : 1.0\n",
      "                 suffix2 = 'on'             male : female =     11.8 : 1.0\n",
      "                 suffix1 = 'v'              male : female =     11.1 : 1.0\n",
      "                 suffix2 = 'ew'             male : female =     11.1 : 1.0\n",
      "                 suffix1 = 'd'              male : female =     11.0 : 1.0\n",
      "                 suffix2 = 'am'             male : female =     10.8 : 1.0\n",
      "                 suffix2 = 'ke'             male : female =     10.3 : 1.0\n",
      "                 suffix2 = 'ig'             male : female =      9.9 : 1.0\n",
      "                 suffix2 = 'ir'             male : female =      9.9 : 1.0\n",
      "                 suffix2 = 'ns'             male : female =      9.9 : 1.0\n",
      "                 suffix2 = 'rk'             male : female =      9.9 : 1.0\n",
      "                 suffix2 = 'rn'             male : female =      9.9 : 1.0\n",
      "                 suffix2 = 'er'             male : female =      9.4 : 1.0\n",
      "                 suffix2 = 'sy'           female : male   =      8.9 : 1.0\n",
      "                 suffix2 = 'ff'             male : female =      8.8 : 1.0\n",
      "                 suffix2 = 'st'             male : female =      8.8 : 1.0\n",
      "                 suffix2 = 'ya'           female : male   =      8.6 : 1.0\n",
      "                 suffix1 = 'o'              male : female =      8.5 : 1.0\n",
      "                 suffix1 = 'r'              male : female =      8.4 : 1.0\n",
      "                 suffix2 = 'go'             male : female =      7.6 : 1.0\n",
      "                 suffix2 = 'ul'             male : female =      7.6 : 1.0\n",
      "                 suffix1 = 'u'              male : female =      7.5 : 1.0\n",
      "                 suffix2 = 'ud'             male : female =      7.4 : 1.0\n",
      "                 suffix2 = 'ro'             male : female =      7.3 : 1.0\n",
      "                 suffix2 = 'ar'             male : female =      6.9 : 1.0\n",
      "                 suffix2 = 'ed'             male : female =      6.8 : 1.0\n",
      "                 suffix2 = 'ee'           female : male   =      6.5 : 1.0\n",
      "                 suffix2 = 'eb'             male : female =      6.4 : 1.0\n",
      "                 suffix2 = 'ev'             male : female =      6.4 : 1.0\n",
      "                 suffix2 = 'lo'             male : female =      6.4 : 1.0\n",
      "                 suffix2 = 'oy'             male : female =      6.4 : 1.0\n",
      "                 suffix2 = 'ha'           female : male   =      6.3 : 1.0\n",
      "                 suffix1 = 'w'              male : female =      6.2 : 1.0\n",
      "                 suffix2 = 'te'           female : male   =      5.9 : 1.0\n",
      "                 suffix1 = 'g'              male : female =      5.8 : 1.0\n",
      "                 suffix2 = 'sh'             male : female =      5.8 : 1.0\n",
      "                 suffix2 = 'or'             male : female =      5.7 : 1.0\n",
      "                 suffix2 = 'ne'           female : male   =      5.6 : 1.0\n",
      "                 suffix2 = 'yn'           female : male   =      5.6 : 1.0\n",
      "                 suffix2 = 'bi'           female : male   =      5.5 : 1.0\n",
      "                 suffix2 = 'es'             male : female =      5.3 : 1.0\n",
      "                 suffix2 = 'nt'             male : female =      5.3 : 1.0\n",
      "                 suffix2 = 'ni'           female : male   =      5.3 : 1.0\n",
      "                 suffix1 = 't'              male : female =      4.8 : 1.0\n",
      "                 suffix1 = 'i'            female : male   =      4.8 : 1.0\n",
      "                 suffix2 = 'tt'             male : female =      4.8 : 1.0\n",
      "                 suffix2 = 'nd'             male : female =      4.8 : 1.0\n",
      "                 suffix1 = 's'              male : female =      4.7 : 1.0\n",
      "                 suffix2 = 'eo'             male : female =      4.6 : 1.0\n",
      "                 suffix1 = 'j'              male : female =      4.2 : 1.0\n",
      "                 suffix1 = 'z'              male : female =      4.2 : 1.0\n",
      "                 suffix2 = 'at'             male : female =      4.1 : 1.0\n",
      "                 suffix2 = 'so'             male : female =      4.1 : 1.0\n",
      "                 suffix1 = 'b'              male : female =      4.1 : 1.0\n",
      "                 suffix2 = 'li'           female : male   =      4.0 : 1.0\n",
      "                 suffix2 = 'yl'           female : male   =      4.0 : 1.0\n",
      "                 suffix2 = 'an'             male : female =      3.8 : 1.0\n",
      "                 suffix2 = 'ko'           female : male   =      3.6 : 1.0\n",
      "                 suffix2 = 'ay'             male : female =      3.4 : 1.0\n",
      "                 suffix2 = 'de'           female : male   =      3.2 : 1.0\n",
      "                 suffix2 = 'ur'             male : female =      3.2 : 1.0\n",
      "                 suffix2 = 'id'             male : female =      3.0 : 1.0\n",
      "                 suffix2 = 'ad'             male : female =      2.9 : 1.0\n",
      "                 suffix2 = 'af'             male : female =      2.9 : 1.0\n",
      "                 suffix2 = 'ag'             male : female =      2.9 : 1.0\n",
      "                 suffix2 = 'me'             male : female =      2.9 : 1.0\n",
      "                 suffix2 = 'ou'             male : female =      2.9 : 1.0\n",
      "                 suffix2 = 'pp'             male : female =      2.9 : 1.0\n",
      "                 suffix2 = 'rr'             male : female =      2.9 : 1.0\n",
      "                 suffix2 = 'we'             male : female =      2.9 : 1.0\n",
      "                 suffix2 = 'gh'             male : female =      2.8 : 1.0\n",
      "                 suffix2 = 'ky'             male : female =      2.8 : 1.0\n",
      "                 suffix2 = 'in'             male : female =      2.7 : 1.0\n",
      "                 suffix2 = 'll'             male : female =      2.7 : 1.0\n",
      "                 suffix2 = 'ot'             male : female =      2.7 : 1.0\n",
      "                 suffix2 = 'ye'           female : male   =      2.7 : 1.0\n",
      "                 suffix2 = 'ab'             male : female =      2.5 : 1.0\n",
      "                 suffix2 = 'ai'             male : female =      2.5 : 1.0\n",
      "                 suffix2 = 'ei'             male : female =      2.5 : 1.0\n",
      "                 suffix2 = 'fy'             male : female =      2.5 : 1.0\n",
      "                 suffix2 = 'rl'             male : female =      2.5 : 1.0\n",
      "                 suffix2 = 'nn'           female : male   =      2.4 : 1.0\n",
      "                 suffix2 = 'ie'           female : male   =      2.4 : 1.0\n",
      "                 suffix2 = 'le'           female : male   =      2.4 : 1.0\n",
      "                 suffix1 = 'n'              male : female =      2.2 : 1.0\n",
      "                 suffix2 = 'il'             male : female =      2.2 : 1.0\n",
      "                 suffix2 = 'ri'           female : male   =      2.2 : 1.0\n",
      "                 suffix1 = 'e'            female : male   =      2.2 : 1.0\n",
      "                 suffix2 = 'oe'             male : female =      2.1 : 1.0\n",
      "                 suffix2 = 'pe'             male : female =      2.1 : 1.0\n",
      "                 suffix2 = 'ae'           female : male   =      2.1 : 1.0\n",
      "                 suffix2 = 'ss'             male : female =      2.1 : 1.0\n",
      "                 suffix2 = 'ty'           female : male   =      2.0 : 1.0\n",
      "                 suffix2 = 've'             male : female =      2.0 : 1.0\n",
      "                 suffix2 = 'se'           female : male   =      1.9 : 1.0\n",
      "                 suffix1 = 'l'              male : female =      1.9 : 1.0\n",
      "                 suffix1 = 'x'              male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'by'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'ez'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'ge'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'ow'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'rm'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'ru'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'um'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'vy'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'yt'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'eg'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'py'             male : female =      1.8 : 1.0\n",
      "                 suffix2 = 'un'             male : female =      1.8 : 1.0\n",
      "                 suffix1 = 'h'              male : female =      1.6 : 1.0\n",
      "                 suffix2 = 'el'             male : female =      1.5 : 1.0\n",
      "                 suffix2 = 'hy'             male : female =      1.5 : 1.0\n",
      "                 suffix2 = 'gi'           female : male   =      1.5 : 1.0\n",
      "                 suffix2 = 'ue'           female : male   =      1.5 : 1.0\n",
      "                 suffix2 = 'ey'             male : female =      1.5 : 1.0\n",
      "                 suffix2 = 'al'             male : female =      1.5 : 1.0\n",
      "                 suffix2 = 'ry'             male : female =      1.4 : 1.0\n",
      "                 suffix2 = 'it'             male : female =      1.4 : 1.0\n",
      "                 suffix2 = 'ce'             male : female =      1.4 : 1.0\n",
      "                 suffix2 = 'ol'             male : female =      1.4 : 1.0\n",
      "                 suffix2 = 'zy'             male : female =      1.4 : 1.0\n",
      "                 suffix2 = 'cy'           female : male   =      1.3 : 1.0\n",
      "                 suffix2 = 'he'           female : male   =      1.3 : 1.0\n",
      "                 suffix2 = 'ny'           female : male   =      1.3 : 1.0\n",
      "                 suffix2 = 'ix'           female : male   =      1.3 : 1.0\n",
      "                 suffix2 = 'rg'           female : male   =      1.3 : 1.0\n",
      "                 suffix2 = 'ah'           female : male   =      1.3 : 1.0\n",
      "                 suffix2 = 'vi'             male : female =      1.3 : 1.0\n",
      "                 suffix2 = 'th'           female : male   =      1.2 : 1.0\n",
      "                 suffix2 = 'my'             male : female =      1.2 : 1.0\n",
      "                 suffix2 = 'is'             male : female =      1.2 : 1.0\n",
      "                 suffix2 = 'ly'           female : male   =      1.2 : 1.0\n",
      "                 suffix1 = 'y'              male : female =      1.2 : 1.0\n",
      "                 suffix2 = 'en'             male : female =      1.1 : 1.0\n",
      "                 suffix2 = 'be'             male : female =      1.1 : 1.0\n",
      "                 suffix2 = 'gy'             male : female =      1.1 : 1.0\n",
      "                 suffix2 = 're'           female : male   =      1.1 : 1.0\n",
      "                 suffix2 = 'fa'             male : female =      1.1 : 1.0\n",
      "                 suffix2 = 'iz'             male : female =      1.1 : 1.0\n",
      "                 suffix2 = 'rb'             male : female =      1.1 : 1.0\n",
      "                 suffix2 = 'wn'             male : female =      1.1 : 1.0\n",
      "                 suffix2 = 'dy'             male : female =      1.0 : 1.0\n",
      "                 suffix2 = 'et'           female : male   =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# showing just in the training set\n",
    "nb3.show_most_informative_features(None) #None will give me all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-rebound",
   "metadata": {},
   "source": [
    "### 4th feature: 1-letter suffix, 2-letter suffix + last trigram + first trigram + first fourgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-effort",
   "metadata": {},
   "source": [
    "######  A combination of features: A name's last letter, last two letters, the last three letters, the first trigram, and the first 4-gram.\n",
    "###### Trigram: a group of three consecutive written units such as letters, syllables, or words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "meaning-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features4(name):\n",
    "        name = name.lower()\n",
    "        return {\n",
    "            'suffix1': name[-1:],\n",
    "            'suffix2': name[-2:],\n",
    "            'last_trigram': name[-3:],\n",
    "            'first_trigram': name[:3], \n",
    "            'first_fourgram': name[:4]\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "daily-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix1': 'h',\n",
       " 'suffix2': 'ah',\n",
       " 'last_trigram': 'rah',\n",
       " 'first_trigram': 'tar',\n",
       " 'first_fourgram': 'tarr'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features4(\"Tarrah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "intelligent-listing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is\n",
      "0.882\n",
      "Test accuracy is\n",
      "0.9\n",
      "\n",
      "Performance metrics for training set: \n",
      "\n",
      "Male precision:  0.912\n",
      "Female precision:  0.9659\n",
      "Male recall:  0.9396\n",
      "Female recall:  0.9497\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9256\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9577\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features4(n), g) for (n,g) in train]\n",
    "dev_test_set = [(gender_features4(n), g) for (n,g) in dev_test]\n",
    "test_set = [(gender_features4(n), g) for (n,g) in test]\n",
    "nb4 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Validation accuracy is')\n",
    "print(nltk.classify.accuracy(nb4, dev_test_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb4, test_set))\n",
    "print(\"\")\n",
    "print(\"Performance metrics for training set: \\n\", )\n",
    "performance_metrics(nb4, train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "champion-transsexual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for validation set: \n",
      "\n",
      "Male precision:  0.8361\n",
      "Female precision:  0.9085\n",
      "Male recall:  0.8407\n",
      "Female recall:  0.9057\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8384\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9071\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for validation set: \\n\", )\n",
    "performance_metrics(nb4, dev_test_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-balloon",
   "metadata": {},
   "source": [
    "#### This is the first feature that suffers quite markedly a dent for both Male F1 Score and Female F1 Score. I think there is an overfitting going on with the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-relay",
   "metadata": {},
   "source": [
    "### 5th Feature: Vowel positions - a combination of ending in vowel, last letter, last three letters, and last two letters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-mills",
   "metadata": {},
   "source": [
    " #### Female names end more often with a vowel than male names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "local-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowel_features(name):\n",
    "    return({'last_is_vowel': (name[-1] in 'aeiouy'),\n",
    "            'last_letter': name[-1],\n",
    "            'last_three': name[-3:],\n",
    "            'last_two': name[-2:]\n",
    "           }\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "authorized-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item[1] for item in labeled_names_dedupped if vowel_features(item[0])['last_is_vowel'] is True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "promotional-intervention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'female': 3779, 'male': 813})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_is_vowel_dist = [item[1] for item in labeled_names_dedupped if vowel_features(item[0])['last_is_vowel'] is True]\n",
    "nltk.FreqDist(last_is_vowel_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-disorder",
   "metadata": {},
   "source": [
    "At first glance, names ending in vowels really has a higher percentage of being female. With this feature being true, we were able to get a male to female ratios is currently at ~ (22:100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-corps",
   "metadata": {},
   "source": [
    "### 6th Feature: Consonent blends - look for 1 or 2 clusters of consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "premier-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consonant_blends(name):\n",
    "    features = {}\n",
    "    temp_name = name\n",
    "    consonant_blends = [\"bl\", \n",
    "                         \"br\", \n",
    "                         \"ch\", \n",
    "                         \"cl\", \n",
    "                         \"cr\", \n",
    "                         \"dr\", \n",
    "                         \"fl\", \n",
    "                         \"fr\", \n",
    "                         \"gl\", \n",
    "                         \"gr\", \n",
    "                         \"pl\", \n",
    "                         \"pr\", \n",
    "                         \"sc\", \n",
    "                         \"sh\", \n",
    "                         \"sk\", \n",
    "                         \"sl\", \n",
    "                         \"sm\", \n",
    "                         \"sn\", \n",
    "                         \"sp\", \n",
    "                         \"st\", \n",
    "                         \"sw\", \n",
    "                         \"th\", \n",
    "                         \"tr\", \n",
    "                         \"tw\", \n",
    "                         \"wh\", \n",
    "                         \"wr\", \n",
    "                         \"sch\", \n",
    "                         \"scr\", \n",
    "                         \"shr\", \n",
    "                         \"sph\", \n",
    "                         \"spl\", \n",
    "                         \"spr\", \n",
    "                         \"squ\", \n",
    "                         \"str\", \n",
    "                         \"thr\"\n",
    "                       ]\n",
    "    clusters = []\n",
    "    for cluster in consonant_blends[::-1]:\n",
    "        if cluster in temp_name:\n",
    "            temp_name = temp_name.replace(cluster, \"\")\n",
    "            clusters.append(cluster)\n",
    "    features[\"consonant_blends_1\"] = clusters[0] if len(clusters) > 0 else None\n",
    "    features[\"consonant_blends_2\"] = clusters[1] if len(clusters) > 1 else None\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "forbidden-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "consonant_blends = [\"bl\", \n",
    "                     \"br\", \n",
    "                     \"ch\", \n",
    "                     \"cl\", \n",
    "                     \"cr\", \n",
    "                     \"dr\", \n",
    "                     \"fl\", \n",
    "                     \"fr\", \n",
    "                     \"gl\", \n",
    "                     \"gr\", \n",
    "                     \"pl\", \n",
    "                     \"pr\", \n",
    "                     \"sc\", \n",
    "                     \"sh\", \n",
    "                     \"sk\", \n",
    "                     \"sl\", \n",
    "                     \"sm\", \n",
    "                     \"sn\", \n",
    "                     \"sp\", \n",
    "                     \"st\", \n",
    "                     \"sw\", \n",
    "                     \"th\", \n",
    "                     \"tr\", \n",
    "                     \"tw\", \n",
    "                     \"wh\", \n",
    "                     \"wr\", \n",
    "                     \"sch\", \n",
    "                     \"scr\", \n",
    "                     \"shr\", \n",
    "                     \"sph\", \n",
    "                     \"spl\", \n",
    "                     \"spr\", \n",
    "                     \"squ\", \n",
    "                     \"str\", \n",
    "                     \"thr\"\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "certified-flooring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thr',\n",
       " 'str',\n",
       " 'squ',\n",
       " 'spr',\n",
       " 'spl',\n",
       " 'sph',\n",
       " 'shr',\n",
       " 'scr',\n",
       " 'sch',\n",
       " 'wr',\n",
       " 'wh',\n",
       " 'tw',\n",
       " 'tr',\n",
       " 'th',\n",
       " 'sw',\n",
       " 'st',\n",
       " 'sp',\n",
       " 'sn',\n",
       " 'sm',\n",
       " 'sl',\n",
       " 'sk',\n",
       " 'sh',\n",
       " 'sc',\n",
       " 'pr',\n",
       " 'pl',\n",
       " 'gr',\n",
       " 'gl',\n",
       " 'fr',\n",
       " 'fl',\n",
       " 'dr',\n",
       " 'cr',\n",
       " 'cl',\n",
       " 'ch',\n",
       " 'br',\n",
       " 'bl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consonant_blends[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "legal-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1=consonant_blends('Beverlie')\n",
    "# f1\n",
    "# type(f1)\n",
    "# f1['consonant_blends_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "further-majority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'female': 547, 'male': 408})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_bl_1_dist = [item[1] for item in labeled_names_dedupped if consonant_blends(item[0])['consonant_blends_1'] is not None]\n",
    "nltk.FreqDist(con_bl_1_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "excited-diesel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'male': 10, 'female': 4})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_bl_2_dist = [item[1] for item in labeled_names_dedupped if consonant_blends(item[0])['consonant_blends_2'] is not None]\n",
    "nltk.FreqDist(con_bl_2_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-firewall",
   "metadata": {},
   "source": [
    "#### As I found out there is never a name that has more than 2 consonant clusters, we are just going to check for consonant_blends1 and consonant_blends2. If there are consonant_blends_2 existed for the name given, it's more likely to be a male name. If there is a consonant_blends_1 existed, it's more likely to be a female name. How does that sound to you? What a simple but yet an effective feature, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-magnet",
   "metadata": {},
   "source": [
    "### 7th Feature: bouba_letters blends & kiki_letters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-great",
   "metadata": {},
   "source": [
    "#### The “bouba/kiki effect” is the robust tendency to associate rounded objects (vs. angular objects) with names that require rounding of the mouth to pronounce, and may reflect synesthesia-like mapping across perceptual modalities. Here we show for the first time a “social” bouba/kiki effect, such that experimental participants associate round names (“Bob,” “Lou”) with round-faced (vs. angular-faced) individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "wicked-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bouba_kiki_features(name):\n",
    "        name=name.lower()\n",
    "        return {\n",
    "            'bouba_letters': len([v for v in name if v in 'blmnuo']),\n",
    "            'kiki_letters':len([v for v in name if v in 'kptiezv']),\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bound-casting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bouba_letters': 1, 'kiki_letters': 2}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bouba_kiki_features('Adirel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "psychological-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built a choose_features function for features 5 thru' 7\n",
    "\n",
    "def choose_features(metric):\n",
    "    train_empty = []\n",
    "    dev_test_empty = [] \n",
    "    test_set_empty = []\n",
    "    if metric == \"vowel_features\":\n",
    "        train1 = [(vowel_features(n), gender) for (n, gender) in labeled_names_dedupped if (n,gender) in train ]\n",
    "        dev_test1 = [(vowel_features(n), gender) for (n, gender) in labeled_names_dedupped if (n,gender) in dev_test ]\n",
    "        test1 = [(vowel_features(n), gender) for (n, gender) in labeled_names_dedupped if (n,gender) in test_set ]\n",
    "        return train1, dev_test1, test1      \n",
    "    elif metric == \"consonant_blends\":\n",
    "        train2 = [(consonant_blends(n), gender) for (n, gender) in labeled_names_dedupped if (n,gender) in train ]\n",
    "        dev_test2 = [(consonant_blends(n), gender) for (n, gender) in labeled_names_dedupped if (n,gender) in dev_test ]\n",
    "        test2 = [(consonant_blends(n), gender) for (n, gender) in labeled_names_dedupped if (n,gender) in test_set ]     \n",
    "        return train2, dev_test2, test2      \n",
    "    elif metric== 'bouba_kiki_features':\n",
    "        train3 = [(bouba_kiki_features(n), gender) for (n, gender) in labeled_names_dedupped if (n,gender) in train ]\n",
    "        dev_test3 = [(bouba_kiki_features(n), gender) for (n, gender) in labeled_names_dedupped if (n,gender) in dev_test ]\n",
    "        test3 = [(bouba_kiki_features(n), gender) for (n, gender) in labeled_names_dedupped if (n,gender) in test_set ]\n",
    "        return train3, dev_test3, test3      \n",
    "    else:\n",
    "        print(\"Invalid Metric\")\n",
    "        return train_empty, dev_test_empty, test_set_empty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-consent",
   "metadata": {},
   "source": [
    "### Feature 5 Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "reliable-reverse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is\n",
      "0.778\n",
      "Test accuracy is\n",
      "0\n",
      "\n",
      "Performance metrics for training set: \n",
      "\n",
      "Male precision:  0.7763\n",
      "Female precision:  0.8923\n",
      "Male recall:  0.8106\n",
      "Female recall:  0.8704\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7931\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8812\n"
     ]
    }
   ],
   "source": [
    "train_set, dev_test_set, test_set = choose_features(metric='vowel_features')\n",
    "\n",
    "nb5 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "\n",
    "print('Validation accuracy is')\n",
    "print(nltk.classify.accuracy(nb5, dev_test_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb5, test_set))\n",
    "print(\"\")\n",
    "print(\"Performance metrics for training set: \\n\", )\n",
    "performance_metrics(nb5, train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "north-clause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for validation set: \n",
      "\n",
      "Male precision:  0.694\n",
      "Female precision:  0.8265\n",
      "Male recall:  0.6978\n",
      "Female recall:  0.8239\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6959\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8252\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for validation set: \\n\", )\n",
    "performance_metrics(nb5, dev_test_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-essence",
   "metadata": {},
   "source": [
    "There is a noticeable dropoff in Male F1 Score while there is 5% decrease in Female F1 Score. There is some overfitting in training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-enhancement",
   "metadata": {},
   "source": [
    "### Feature 6 Performance Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "earlier-voice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is\n",
      "0.648\n",
      "Test accuracy is\n",
      "0\n",
      "\n",
      "Performance metrics for training set: \n",
      "\n",
      "Male precision:  0.7032\n",
      "Female precision:  0.6519\n",
      "Male recall:  0.0491\n",
      "Female recall:  0.9885\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0919\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857\n"
     ]
    }
   ],
   "source": [
    "train_set, dev_test_set, test_set = choose_features(metric='consonant_blends')\n",
    "\n",
    "nb6 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "\n",
    "print('Validation accuracy is')\n",
    "print(nltk.classify.accuracy(nb6, dev_test_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb6, test_set))\n",
    "print(\"\")\n",
    "print(\"Performance metrics for training set: \\n\", )\n",
    "performance_metrics(nb6, train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "micro-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for validation set: \n",
      "\n",
      "Male precision:  0.8\n",
      "Female precision:  0.6449\n",
      "Male recall:  0.044\n",
      "Female recall:  0.9937\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0833\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7822\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for validation set: \\n\", )\n",
    "performance_metrics(nb6, dev_test_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-report",
   "metadata": {},
   "source": [
    "As there is virtually no change for both Male F1 Score and Female F1 score, I don't see there is any evidence of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-capability",
   "metadata": {},
   "source": [
    "### Feature 7 Performance Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dominant-documentary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is\n",
      "0.638\n",
      "Test accuracy is\n",
      "0\n",
      "\n",
      "Performance metrics for training set: \n",
      "\n",
      "Male precision:  0.5417\n",
      "Female precision:  0.6438\n",
      "Male recall:  0.0059\n",
      "Female recall:  0.9972\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0116\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7824\n"
     ]
    }
   ],
   "source": [
    "train_set, dev_test_set, test_set = choose_features(metric='bouba_kiki_features')\n",
    "\n",
    "nb7 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "\n",
    "print('Validation accuracy is')\n",
    "print(nltk.classify.accuracy(nb7, dev_test_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb7, test_set))\n",
    "print(\"\")\n",
    "print(\"Performance metrics for training set: \\n\", )\n",
    "performance_metrics(nb7, train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "verbal-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for validation set: \n",
      "\n",
      "Male precision:  0.6\n",
      "Female precision:  0.6384\n",
      "Male recall:  0.0165\n",
      "Female recall:  0.9937\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0321\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7774\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for validation set: \\n\", )\n",
    "performance_metrics(nb7, dev_test_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-translator",
   "metadata": {},
   "source": [
    "As there is almost no change to the Female F1 Score, and slight uptick in Male F1 Score, there is no indications of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-gallery",
   "metadata": {},
   "source": [
    "### 8th Feature: phonetic gender score - leveraging get_gender( ) \n",
    "#### The result will be one of unknown (name not found), andy (androgynous), male, female, mostly_male, or mostly_female. The difference between andy and unknown is that the former is found to have the same probability to be male than to be female, while the later means that the name wasn’t found in the database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "compact-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing d from the gender_features8() func to avoid creating many Detectors, as each creation means reading the \n",
    "# data file\n",
    "d = gender.Detector(case_sensitive=False)\n",
    "\n",
    "def gender_features8(name):\n",
    "    return {'phonetic_gender_score':  d.get_gender(name)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "radical-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phonetic_gender_score': 'female'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features8('Ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "mighty-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is\n",
      "0.822\n",
      "Test accuracy is\n",
      "0.864\n",
      "\n",
      "Performance metrics for training set: \n",
      "\n",
      "Male precision:  0.9108\n",
      "Female precision:  0.8162\n",
      "Male recall:  0.6078\n",
      "Female recall:  0.967\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.729\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8852\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features8(n), g) for (n,g) in train]\n",
    "dev_test_set = [(gender_features8(n), g) for (n,g) in dev_test]\n",
    "test_set = [(gender_features8(n), g) for (n,g) in test]\n",
    "nb8 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Validation accuracy is')\n",
    "print(nltk.classify.accuracy(nb8, dev_test_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb8, test_set))\n",
    "print(\"\")\n",
    "print(\"Performance metrics for training set: \\n\", )\n",
    "performance_metrics(nb8, train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fitting-converter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for validation set: \n",
      "\n",
      "Male precision:  0.8843\n",
      "Female precision:  0.8021\n",
      "Male recall:  0.5879\n",
      "Female recall:  0.956\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7063\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8723\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for validation set: \\n\", )\n",
    "performance_metrics(nb8, dev_test_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-average",
   "metadata": {},
   "source": [
    "As there is virutally no dropoffs from bot Male F1 Score and Female F1 Score, I'm ascertained that there is no issues of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "wrong-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   phonetic_gender_score = 'female'       female : male   =     41.9 : 1.0\n",
      "   phonetic_gender_score = 'male'           male : female =     23.6 : 1.0\n",
      "   phonetic_gender_score = 'mostly_male'    male : female =      7.1 : 1.0\n",
      "   phonetic_gender_score = 'mostly_female' female : male   =      3.4 : 1.0\n",
      "   phonetic_gender_score = 'andy'           male : female =      2.2 : 1.0\n",
      "   phonetic_gender_score = 'unknown'      female : male   =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb8.show_most_informative_features(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-graph",
   "metadata": {},
   "source": [
    "###### There phonetic score really are performing quite well just by looking at the results from the function show_most_informative_features( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-treaty",
   "metadata": {},
   "source": [
    "#### Let's merge the features that do not result in overfitting into one feature as a classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "separated-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features_finalized(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0]\n",
    "    features[\"last_letter\"] = name[-1]\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name)\n",
    "\n",
    "    features[\"suffix1\"] = name[-1:] \n",
    "    features[\"suffix2\"] = name[-2:] \n",
    "        \n",
    "    features = {}\n",
    "    temp_name = name\n",
    "    consonant_blends = [\"bl\", \n",
    "                         \"br\", \n",
    "                         \"ch\", \n",
    "                         \"cl\", \n",
    "                         \"cr\", \n",
    "                         \"dr\", \n",
    "                         \"fl\", \n",
    "                         \"fr\", \n",
    "                         \"gl\", \n",
    "                         \"gr\", \n",
    "                         \"pl\", \n",
    "                         \"pr\", \n",
    "                         \"sc\", \n",
    "                         \"sh\", \n",
    "                         \"sk\", \n",
    "                         \"sl\", \n",
    "                         \"sm\", \n",
    "                         \"sn\", \n",
    "                         \"sp\", \n",
    "                         \"st\", \n",
    "                         \"sw\", \n",
    "                         \"th\", \n",
    "                         \"tr\", \n",
    "                         \"tw\", \n",
    "                         \"wh\", \n",
    "                         \"wr\", \n",
    "                         \"sch\", \n",
    "                         \"scr\", \n",
    "                         \"shr\", \n",
    "                         \"sph\", \n",
    "                         \"spl\", \n",
    "                         \"spr\", \n",
    "                         \"squ\", \n",
    "                         \"str\", \n",
    "                         \"thr\"\n",
    "                       ]\n",
    "    clusters = []\n",
    "    for cluster in consonant_blends[::-1]:\n",
    "        if cluster in temp_name:\n",
    "            temp_name = temp_name.replace(cluster, \"\")\n",
    "            clusters.append(cluster)\n",
    "    features[\"consonant_blends_1\"] = clusters[0] if len(clusters) > 0 else None\n",
    "    features[\"consonant_blends_2\"] = clusters[1] if len(clusters) > 1 else None    \n",
    "    \n",
    "    features['bouba_letters'] = len([v for v in name if v in 'blmnuo'])\n",
    "    features['kiki_letters'] = len([v for v in name if v in 'kptiezv'])\n",
    "    \n",
    "    features['phonetic_gender_score'] =  d.get_gender(name)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "classified-judge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is\n",
      "0.822\n",
      "Test accuracy is\n",
      "0.866\n",
      "\n",
      "Performance metrics for training set: \n",
      "\n",
      "Male precision:  0.9048\n",
      "Female precision:  0.8258\n",
      "Male recall:  0.6339\n",
      "Female recall:  0.963\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7455\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8891\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features_finalized(n), g) for (n,g) in train]\n",
    "dev_test_set = [(gender_features_finalized(n), g) for (n,g) in dev_test]\n",
    "test_set = [(gender_features_finalized(n), g) for (n,g) in test]\n",
    "nb9 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Validation accuracy is')\n",
    "print(nltk.classify.accuracy(nb9, dev_test_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb9, test_set))\n",
    "print(\"\")\n",
    "print(\"Performance metrics for training set: \\n\", )\n",
    "performance_metrics(nb9, train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "considered-volunteer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for validation set: \n",
      "\n",
      "Male precision:  0.872\n",
      "Female precision:  0.8053\n",
      "Male recall:  0.5989\n",
      "Female recall:  0.9497\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7101\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8716\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for validation set: \\n\", )\n",
    "performance_metrics(nb9, dev_test_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "naughty-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for test set: \n",
      "\n",
      "Male precision:  0.8936\n",
      "Female precision:  0.8552\n",
      "Male recall:  0.7079\n",
      "Female recall:  0.9534\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Male F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Female F1 Score: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9016\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics for test set: \\n\", )\n",
    "performance_metrics(nb9, test_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "spectacular-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate errors\n",
    "def generate_errors(classifier, dataset): \n",
    "    \n",
    "    errors = [] \n",
    "\n",
    "    for (name, tag) in dataset:\n",
    "        guess = classifier.classify(gender_features_finalized(name)) \n",
    "        if guess != tag: \n",
    "            errors.append((tag, guess, name))\n",
    "            \n",
    "    return errors\n",
    "#Function to print error\n",
    "def show_errors(errors, n = None):\n",
    "   \n",
    "    if n is not None: errors = errors[:n]\n",
    "            \n",
    "    for (tag, guess, name) in sorted(errors): \n",
    "        print('label=%-8s guess=%-8s name=%-30s' %(tag, guess, name))\n",
    "    print(len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bottom-group",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=female   guess=male     name=Blondelle                     \n",
      "label=female   guess=male     name=Demeter                       \n",
      "label=female   guess=male     name=Devan                         \n",
      "label=female   guess=male     name=Fabrice                       \n",
      "label=female   guess=male     name=Franni                        \n",
      "label=female   guess=male     name=Jammie                        \n",
      "label=female   guess=male     name=Jessy                         \n",
      "label=female   guess=male     name=Karol                         \n",
      "label=female   guess=male     name=Lian                          \n",
      "label=female   guess=male     name=Lilyan                        \n",
      "label=female   guess=male     name=Lulu                          \n",
      "label=female   guess=male     name=Marin                         \n",
      "label=female   guess=male     name=Sile                          \n",
      "label=female   guess=male     name=Tomi                          \n",
      "label=female   guess=male     name=Ventura                       \n",
      "label=female   guess=male     name=Wren                          \n",
      "label=male     guess=female   name=Adolpho                       \n",
      "label=male     guess=female   name=Aguste                        \n",
      "label=male     guess=female   name=Alfonse                       \n",
      "label=male     guess=female   name=Ambrosi                       \n",
      "label=male     guess=female   name=Antin                         \n",
      "label=male     guess=female   name=Baldwin                       \n",
      "label=male     guess=female   name=Barn                          \n",
      "label=male     guess=female   name=Bartie                        \n",
      "label=male     guess=female   name=Benjamen                      \n",
      "label=male     guess=female   name=Beowulf                       \n",
      "label=male     guess=female   name=Berchtold                     \n",
      "label=male     guess=female   name=Binky                         \n",
      "label=male     guess=female   name=Bjorne                        \n",
      "label=male     guess=female   name=Briggs                        \n",
      "label=male     guess=female   name=Chaddie                       \n",
      "label=male     guess=female   name=Chane                         \n",
      "label=male     guess=female   name=Derby                         \n",
      "label=male     guess=female   name=Dunc                          \n",
      "label=male     guess=female   name=Ephram                        \n",
      "label=male     guess=female   name=Erastus                       \n",
      "label=male     guess=female   name=Garcia                        \n",
      "label=male     guess=female   name=Garv                          \n",
      "label=male     guess=female   name=Garvy                         \n",
      "label=male     guess=female   name=Gomer                         \n",
      "label=male     guess=female   name=Hall                          \n",
      "label=male     guess=female   name=Hanford                       \n",
      "label=male     guess=female   name=Haven                         \n",
      "label=male     guess=female   name=Heathcliff                    \n",
      "label=male     guess=female   name=Herbie                        \n",
      "label=male     guess=female   name=Hiram                         \n",
      "label=male     guess=female   name=Ignacius                      \n",
      "label=male     guess=female   name=Jefferey                      \n",
      "label=male     guess=female   name=Jessey                        \n",
      "label=male     guess=female   name=Kaiser                        \n",
      "label=male     guess=female   name=Kelwin                        \n",
      "label=male     guess=female   name=Knox                          \n",
      "label=male     guess=female   name=Lon                           \n",
      "label=male     guess=female   name=Matthus                       \n",
      "label=male     guess=female   name=Merlin                        \n",
      "label=male     guess=female   name=Mikey                         \n",
      "label=male     guess=female   name=Morrie                        \n",
      "label=male     guess=female   name=Mortie                        \n",
      "label=male     guess=female   name=Mugsy                         \n",
      "label=male     guess=female   name=Northrop                      \n",
      "label=male     guess=female   name=Paddie                        \n",
      "label=male     guess=female   name=Pascale                       \n",
      "label=male     guess=female   name=Phineas                       \n",
      "label=male     guess=female   name=Rabbi                         \n",
      "label=male     guess=female   name=Ransom                        \n",
      "label=male     guess=female   name=Richmond                      \n",
      "label=male     guess=female   name=Richy                         \n",
      "label=male     guess=female   name=Rube                          \n",
      "label=male     guess=female   name=Ruddy                         \n",
      "label=male     guess=female   name=Sarge                         \n",
      "label=male     guess=female   name=Sergeant                      \n",
      "label=male     guess=female   name=Sheff                         \n",
      "label=male     guess=female   name=Shorty                        \n",
      "label=male     guess=female   name=Slade                         \n",
      "label=male     guess=female   name=Somerset                      \n",
      "label=male     guess=female   name=Sully                         \n",
      "label=male     guess=female   name=Tarrance                      \n",
      "label=male     guess=female   name=Thaddus                       \n",
      "label=male     guess=female   name=Thebault                      \n",
      "label=male     guess=female   name=Thornie                       \n",
      "label=male     guess=female   name=Titos                         \n",
      "label=male     guess=female   name=Toddie                        \n",
      "label=male     guess=female   name=Townsend                      \n",
      "label=male     guess=female   name=Tuckie                        \n",
      "label=male     guess=female   name=Tucky                         \n",
      "label=male     guess=female   name=Walsh                         \n",
      "label=male     guess=female   name=Waylen                        \n",
      "label=male     guess=female   name=Winslow                       \n",
      "label=male     guess=female   name=Yule                          \n",
      "89\n"
     ]
    }
   ],
   "source": [
    "# Show error in devtest\n",
    "show_errors(generate_errors(nb9, dev_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-confusion",
   "metadata": {},
   "source": [
    "#### Out of 500 names in the validation set, we have incorrectly classified 89 names, which is essentially 82.2 accuracy entails. There are really no additional hyperparamter tuning that can be done. We can move onto the test set as it's very respectable and within acceptable tolerance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-place",
   "metadata": {},
   "source": [
    "#### Conclusions: \n",
    "##### The overall accuracy of the test set is 86.6 % while other performance metrics are as follows, \n",
    "| Gender | Metric | Percentage |\n",
    "| --- | --- | --- |\n",
    "| Male | precision | 89.36 |\n",
    "| Female | precision | 85.52 |\n",
    "| Male | recall | 70.79 |\n",
    "| Female | recall | 95.34 |\n",
    "| Male | F1 Score | 79 |\n",
    "| Female | F1 Score | 90.16 |\n",
    "\n",
    "#### and if you compare that with the results from the validation set, you can see that we got a set of better scores for F-measure, which is expected.\n",
    "\n",
    "| Gender | Metric | Percentage |\n",
    "| --- | --- | --- |\n",
    "| Male | precision | 87.2 |\n",
    "| Female | precision | 80.53 |\n",
    "| Male | recall | 59.89 |\n",
    "| Female | recall | 94.97 |\n",
    "| Male | F1 Score | 71.01 |\n",
    "| Female | F1 Score | 87.16 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-oregon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
